{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bc9088f-1a49-422b-889a-6aa3cfdd3324",
   "metadata": {},
   "source": [
    "# Train Semantic Segmentation\n",
    "\n",
    "* Define `GarrulusAoiDataModule` that uses `RandomBatchAoiSampler` for the train data\n",
    "* [`Update 23.08.2024`]: Test and validation also use `RandomBatchAoiSampler`, ToDo: `GridAoiSampler`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca6caa6-cad4-44e1-b1a4-4ed08ef326a8",
   "metadata": {},
   "source": [
    "## Create Garrulus AOI Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7e1406-51fc-40ea-bf18-7354260b2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "from torchgeo.models import ResNet18_Weights, ResNet50_Weights\n",
    "\n",
    "from gdl.datamodules.geo import GarrulusAoiDataModule\n",
    "from gdl.trainers.segmentation import GarrulusSemanticSegmentationTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991bdd0c-d85d-4962-bd1f-e48d1cdd7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_path='../../../field-D/grid-10m-squares/grid-10m-squares.shp'\n",
    "fenced_area_path='../../../field-D/boundary-shape/boundary-shape.shp'\n",
    "raster_image_root_path = \"../../../field-D\"\n",
    "mask_root_path = \"../../../field-D/d-RGB-9mm-mask\"\n",
    "\n",
    "batch_size = 64\n",
    "size_lims = (128,256) # size of the window to sample (min,max)\n",
    "length = 1000 # the number of data to sample from the raster image given the size limits\n",
    "img_size = 224 # image size for the model input. since the sample windows vary, they will be transformed to img_size\n",
    "\n",
    "gdm_aoi = GarrulusAoiDataModule(\n",
    "    raster_image_path=raster_image_root_path,\n",
    "    mask_path=mask_root_path,\n",
    "    grid_shape_path=grid_path,\n",
    "    fenced_area_shape_path=fenced_area_path,\n",
    "    batch_size=batch_size,\n",
    "    size_lims=size_lims,\n",
    "    img_size=img_size,\n",
    "    class_set=5,\n",
    "    length=length\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78b139c-c4f3-45bb-a43a-f8de62d2776a",
   "metadata": {},
   "source": [
    "## Create Segmentation Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4891cc-4666-4c17-9db9-fdce07ce6540",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 16\n",
    "max_epochs = 100\n",
    "fast_dev_run = False\n",
    "num_classes = 5\n",
    "\n",
    "accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "default_root_dir = os.path.join(\"./logs\", \"experiments\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\", dirpath=default_root_dir, save_top_k=1, save_last=True\n",
    ")\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=10)\n",
    "logger = TensorBoardLogger(save_dir=default_root_dir, name=\"all_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f110e3-b628-4564-924d-21cdeab49036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create segmentationt ask\n",
    "task = GarrulusSemanticSegmentationTask(\n",
    "    model = 'unet',\n",
    "    backbone = 'resnet50',\n",
    "    loss=\"ce\",\n",
    "    weights=ResNet50_Weights.SENTINEL2_RGB_SECO,\n",
    "    in_channels=3,\n",
    "    num_classes=num_classes,\n",
    "    lr=0.001,\n",
    "    patience=5,\n",
    "    # labels=[\"BACKGROUND\",\"CWD\",\"MISC\",\"STUMP\",\"VEGETATION\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e27fac0-bb1a-4be5-9a6e-4450a0ebc0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62a67c68-7ad6-4ef7-9bab-a70af10cd8b1",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642deab2-7037-43cb-8398-e6861b45d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "    fast_dev_run=fast_dev_run,\n",
    "    log_every_n_steps=1,\n",
    "    logger=logger,\n",
    "    min_epochs=80,\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    strategy=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f32b7a3-b154-4397-a747-5c90892b4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=task, datamodule=gdm_aoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689aa0a4-b56b-4698-9536-40d081634698",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e2fa3a-7fd1-40fe-a21a-43b5ce1b3239",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model=task, datamodule=gdm_aoi, ckpt_path=\"logs/experiments/last-v2.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed0d407-816d-49f2-8170-3e97f98d00f2",
   "metadata": {},
   "source": [
    "### Prediction (Inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c45388-68e7-40ce-b2d6-4e9907140bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(model=task, datamodule=gdm_aoi, \n",
    "                ckpt_path=\"logs/experiments/last-v2.ckpt\", return_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ee089c-a128-453c-b804-bd01974db683",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"logs/experiments/last-v2.ckpt\")\n",
    "task.load_state_dict(model['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11414fd7-8035-46e2-a317-4b77a084ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize prediction\n",
    "num_samples = 10\n",
    "for batch in gdm_aoi.test_dataloader():\n",
    "    image = batch['image']\n",
    "    mask = batch['mask']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = task(image)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "    for i in range(num_samples):\n",
    "        sample = {}\n",
    "        sample['image'] = image[i]\n",
    "        sample['mask'] = mask[i]\n",
    "        sample['prediction'] = preds[i]\n",
    "        gdm_aoi.dataset.plot(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff1b179-22e1-410e-8df2-437707cd4dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
